import argparse
import json
import os
import re
import time
from datetime import datetime
from urllib.parse import urljoin

import pandas as pd
import requests

# ç”¨äºæ”¶é›†é¢æ¿ä¿¡æ¯çš„å…¨å±€åˆ—è¡¨
panel_info_list = []


def extract_panels_info(dashboard_data, folder_name, dashboard_title, dashboard_uid):
    """
    ä»ä»ªè¡¨ç›˜æ•°æ®ä¸­æå–é¢æ¿ä¿¡æ¯
    """
    panels = []

    def process_panel(panel, parent_title=None):
        """é€’å½’å¤„ç†é¢æ¿å’Œå­é¢æ¿"""
        if panel.get("type") == "row":
            for child in panel.get("panels", []):
                process_panel(child, parent_title=panel.get("title"))
            return

        # è·³è¿‡è¡Œé¢æ¿ï¼ˆrow panelï¼‰å’Œç‰¹æ®Šç±»å‹
        if panel.get("type") in ["header"]:
            return

        # æå–é¢æ¿åŸºæœ¬ä¿¡æ¯
        panel_info = {
            "folder_name": folder_name,
            "dashboard_title": dashboard_title,
            "dashboard_uid": dashboard_uid,
            "panel_id": panel.get("id"),
            "panel_title": panel.get("title") or "æ— æ ‡é¢˜é¢æ¿",
            "panel_type": panel.get("type") or "æœªçŸ¥ç±»å‹",
            "datasource": panel.get("datasource"),
            "description": panel.get("description") or "",
            "parent_panel": parent_title,
            "has_data": "",  # ç•™ç©ºç”¨äºåç»­å¡«å†™
            "migration_status": "",  # ç•™ç©ºç”¨äºåç»­å¡«å†™
            "notes": "",  # ç•™ç©ºç”¨äºå¤‡æ³¨
        }

        # æ·»åŠ åˆ°å…¨å±€åˆ—è¡¨
        panels.append(panel_info)

        # å¤„ç†å­é¢æ¿ï¼ˆå¦‚è¡Œå†…çš„é¢æ¿ï¼‰
        for child in panel.get("panels", []):
            process_panel(child, parent_title=panel.get("title"))

    # å¤„ç†æ‰€æœ‰é¡¶çº§é¢æ¿
    for panel in dashboard_data.get("panels", []):
        process_panel(panel)

    # å¤„ç†æ¨¡æ¿å˜é‡ï¼ˆä½œä¸ºç‰¹æ®Šé¢æ¿ï¼‰
    for template in dashboard_data.get("templating", {}).get("list", []):
        panels.append(
            {
                "folder_name": folder_name,
                "dashboard_title": dashboard_title,
                "dashboard_uid": dashboard_uid,
                "panel_id": f"var_{template.get('name')}",
                "panel_title": template.get("label") or template.get("name"),
                "panel_type": "template_variable",
                "datasource": "",
                "description": template.get("description") or "",
                "parent_panel": "",
                "has_data": "",
                "migration_status": "",
                "notes": "",
            }
        )

    return panels


def get_folders(api_url, api_key, api_cookie):
    """è·å–æ‰€æœ‰æ–‡ä»¶å¤¹çš„IDå’Œåç§°æ˜ å°„"""
    url = urljoin(api_url, "api/folders")
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Cookie": api_cookie,
    }

    try:
        response = requests.get(url, headers=headers, timeout=30)
        response.raise_for_status()
        folders = response.json()
        return {folder["title"]: folder["id"] for folder in folders}
    except Exception as e:
        print(f"è·å–æ–‡ä»¶å¤¹å¤±è´¥: {e}")
        return {}


def get_dashboards_in_folder(api_url, api_key, api_cookie, folder_id):
    """è·å–æŒ‡å®šæ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰ä»ªè¡¨ç›˜UID"""
    url = urljoin(api_url, "api/search")
    headers = {"Authorization": f"Bearer {api_key}", "Cookie": api_cookie}
    params = {"type": "dash-db", "folderIds": folder_id}

    try:
        response = requests.get(url, headers=headers, params=params, timeout=30)
        response.raise_for_status()
        dashboards = response.json()
        return [{"uid": db["uid"], "title": db["title"]} for db in dashboards]
    except Exception as e:
        print(f"è·å–æ–‡ä»¶å¤¹ä¸­çš„ä»ªè¡¨ç›˜å¤±è´¥: {e}")
        return []


def export_dashboard(
    api_url, api_key, api_cookie, dashboard_info, folder_name, output_dir
):
    """å¯¼å‡ºå•ä¸ªä»ªè¡¨ç›˜åˆ°JSONæ–‡ä»¶"""
    dashboard_uid = dashboard_info["uid"]
    dashboard_title = dashboard_info["title"]

    url = urljoin(api_url, f"api/dashboards/uid/{dashboard_uid}")
    headers = {"Authorization": f"Bearer {api_key}", "Cookie": api_cookie}

    try:
        response = requests.get(url, headers=headers, timeout=30)
        response.raise_for_status()
        dashboard_data = response.json()

        # è·å–ä»ªè¡¨ç›˜æ ‡é¢˜ç”¨äºæ–‡ä»¶å
        title = dashboard_data["dashboard"].get("title", dashboard_uid)
        # æ¸…ç†æ–‡ä»¶åä¸­çš„éæ³•å­—ç¬¦
        safe_title = "".join(c for c in title if c.isalnum() or c in " _-")

        # ä¿å­˜JSONæ–‡ä»¶
        file_path = os.path.join(output_dir, f"{safe_title}_{dashboard_uid}.json")
        with open(file_path, "w", encoding="utf-8") as f:
            json.dump(dashboard_data["dashboard"], f, indent=2)

        print(f"âœ… æˆåŠŸå¯¼å‡º: {title} -> {file_path}")

        # æå–é¢æ¿ä¿¡æ¯
        panels = extract_panels_info(dashboard_data["dashboard"], folder_name, dashboard_title, dashboard_uid)

        # æ·»åŠ åˆ°å…¨å±€åˆ—è¡¨
        global panel_info_list
        panel_info_list.extend(panels)

        return True, len(panels)
    except Exception as e:
        print(f"âŒ å¯¼å‡ºä»ªè¡¨ç›˜ {dashboard_uid} å¤±è´¥: {e}")
        return False


def generate_excel_report(panel_info_list, output_dir):
    """ç”ŸæˆExcelæŠ¥å‘Š"""

    def remove_illegal_chars(value):
        """ç§»é™¤å­—ç¬¦ä¸²ä¸­çš„éæ³•å­—ç¬¦"""
        if isinstance(value, str):
            return re.sub(r"[\x00-\x1F\x7F]", "", value)
        return value

    def clean_data(panel_info_list):
        """æ¸…ç†é¢æ¿ä¿¡æ¯åˆ—è¡¨ä¸­çš„éæ³•å­—ç¬¦"""
        return [{key: remove_illegal_chars(value) for key, value in panel.items()} for panel in panel_info_list]

    if not panel_info_list:
        print("âš ï¸ æ²¡æœ‰é¢æ¿ä¿¡æ¯å¯ç”ŸæˆæŠ¥å‘Š")
        return

    # æ¸…ç†æ•°æ®
    cleaned_panel_info_list = clean_data(panel_info_list)

    # åˆ›å»ºDataFrame
    df = pd.DataFrame(cleaned_panel_info_list)

    # é‡æ–°æ’åºåˆ—é¡ºåº
    column_order = [
        "folder_name",
        "dashboard_title",
        "dashboard_uid",
        "panel_id",
        "panel_title",
        "panel_type",
        "datasource",
        "description",
        "parent_panel",
        "has_data",
        "migration_status",
        "notes",
    ]
    df = df[column_order]

    # ç”ŸæˆExcelæ–‡ä»¶è·¯å¾„
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    excel_path = os.path.join(output_dir, f"grafana_panels_report_{timestamp}.xlsx")

    # ä¿å­˜Excelæ–‡ä»¶
    with pd.ExcelWriter(excel_path, engine="openpyxl") as writer:
        df.to_excel(writer, index=False, sheet_name="Panels Report")

        # è·å–å·¥ä½œç°¿å’Œå·¥ä½œè¡¨å¯¹è±¡ä»¥è®¾ç½®åˆ—å®½
        worksheet = writer.sheets["Panels Report"]

        # è®¾ç½®åˆ—å®½
        column_widths = {
            "folder_name": 20,
            "dashboard_title": 30,
            "dashboard_uid": 15,
            "panel_id": 10,
            "panel_title": 30,
            "panel_type": 15,
            "datasource": 25,
            "description": 40,
            "parent_panel": 20,
            "has_data": 15,
            "migration_status": 20,
            "notes": 40,
        }

        for idx, col in enumerate(df.columns):
            worksheet.column_dimensions[chr(65 + idx)].width = column_widths.get(
                col, 15
            )

    print(f"ğŸ“Š ExcelæŠ¥å‘Šå·²ç”Ÿæˆ: {excel_path}")
    return excel_path


def export_dashboard_by_folder_name():
    """
    æ‰¹é‡å¯¼å‡ºGrafanaæ–‡ä»¶å¤¹ä¸­çš„ä»ªè¡¨ç›˜å¹¶å°†ä»ªè¡¨ç›˜å’Œé¢æ¿çš„åŸºæœ¬ä¿¡æ¯ä¿å­˜åˆ°Excelæ–‡ä»¶
    ä¸¤ç§ç”¨æ³•ï¼š
    ç”¨æ³•ä¸€ï¼špython export_dashboard_by_folder_name.py --url https://xxxgrafana.com/grafana-xxx/ --key "xxxx" --cookie "xxxx" --folders-file "./folders.txt"
    ç”¨æ³•äºŒï¼špython export_dashboard_by_folder_name.py --url https://xxxgrafana.com/grafana-xxx/ --key "xxxx" --cookie "xxxx" --folders "folder1" "folder2"
    """
    parser = argparse.ArgumentParser(description="æ‰¹é‡å¯¼å‡ºGrafanaæ–‡ä»¶å¤¹ä¸­çš„ä»ªè¡¨ç›˜")
    parser.add_argument(
        "--url", required=True, help="GrafanaåŸºç¡€URL (e.g. http://localhost:3000)"
    )
    parser.add_argument("--key", required=True, help="Grafana APIå¯†é’¥")
    parser.add_argument("--cookie", required=True, help="Grafana APIçš„cookieå€¼")
    parser.add_argument(
        "--folders", nargs="*", default=[], help="è¦å¯¼å‡ºçš„æ–‡ä»¶å¤¹åç§°åˆ—è¡¨"
    )
    parser.add_argument(
        "--folders-file", help="åŒ…å«æ–‡ä»¶å¤¹åç§°åˆ—è¡¨çš„æ–‡ä»¶è·¯å¾„ï¼ˆæ¯è¡Œä¸€ä¸ªæ–‡ä»¶å¤¹åç§°ï¼‰"
    )
    parser.add_argument("--output", default="./grafana_export", help="è¾“å‡ºç›®å½•è·¯å¾„")

    args = parser.parse_args()

    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(args.output, exist_ok=True)

    # è·å–æ–‡ä»¶å¤¹æ˜ å°„
    folder_map = get_folders(args.url, args.key, args.cookie)
    if not folder_map:
        print("æ— æ³•è·å–æ–‡ä»¶å¤¹ä¿¡æ¯ï¼Œè¯·æ£€æŸ¥URLå’ŒAPIå¯†é’¥")
        return

    if args.folders_file:
        script_dir = os.path.dirname(os.path.abspath(__file__))
        args.folders_file = os.path.join(script_dir, args.folders_file)
        try:
            with open(args.folders_file, encoding="utf-8") as f:
                target_folders = [line.strip() for line in f if line.strip()]
                print(f"ä»æ–‡ä»¶ {args.folders_file} è¯»å– {len(target_folders)} ä¸ªæ–‡ä»¶å¤¹")
        except Exception as e:
            print(f"è¯»å–æ–‡ä»¶å¤¹åˆ—è¡¨æ–‡ä»¶å¤±è´¥: {e}")
            return
    else:
        target_folders = args.folders
        print(f"é€šè¿‡å‘½ä»¤è¡Œå‚æ•°--foldersæŒ‡å®š  {len(target_folders)} ä¸ªæ–‡ä»¶å¤¹")

    if not target_folders:
        print("âš ï¸ æ²¡æœ‰æŒ‡å®šè¦å¯¼å‡ºçš„æ–‡ä»¶å¤¹ï¼Œè¯·ä½¿ç”¨ --folders æˆ– --folders-file")
        return

    # å¤„ç†æ¯ä¸ªç›®æ ‡æ–‡ä»¶å¤¹
    for folder_name in target_folders:
        if folder_name not in folder_map:
            print(f"âš ï¸ æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {folder_name}")
            continue

        folder_id = folder_map[folder_name]
        print(f"\nğŸ“‚ å¤„ç†æ–‡ä»¶å¤¹: {folder_name} (ID: {folder_id})")

        # åˆ›å»ºå­ç›®å½•
        folder_output = os.path.join(args.output, folder_name)
        os.makedirs(folder_output, exist_ok=True)

        # è·å–æ–‡ä»¶å¤¹ä¸­çš„ä»ªè¡¨ç›˜
        dashboards = get_dashboards_in_folder(
            args.url, args.key, args.cookie, folder_id
        )
        if not dashboards:
            print(f"æ–‡ä»¶å¤¹ä¸­æ²¡æœ‰ä»ªè¡¨ç›˜: {folder_name}")
            continue

        print(f"æ‰¾åˆ° {len(dashboards)} ä¸ªä»ªè¡¨ç›˜")

        # å¯¼å‡ºæ‰€æœ‰ä»ªè¡¨ç›˜å¹¶æ”¶é›†é¢æ¿ä¿¡æ¯
        success_count = 0
        total_panels = 0
        for dashboard in dashboards:
            success, panel_count = export_dashboard(
                args.url, args.key, args.cookie, dashboard, folder_name, folder_output
            )

            if success:
                success_count += 1
                total_panels += panel_count
                print(f"  åŒ…å« {panel_count} ä¸ªé¢æ¿")

            # æ·»åŠ å»¶è¿Ÿé¿å…è¯·æ±‚è¿‡è½½
            time.sleep(0.5)

        print(f"\nğŸ“Š å¯¼å‡ºæ‘˜è¦: {folder_name}")
        print(f"  ä»ªè¡¨ç›˜: {success_count}/{len(dashboards)} æˆåŠŸ")
        print(f"  é¢æ¿æ€»æ•°: {total_panels}")
        print(f"  ä¿å­˜ä½ç½®: {os.path.abspath(folder_output)}")

    # ç”ŸæˆExcelæŠ¥å‘Š
    if panel_info_list:
        excel_path = generate_excel_report(panel_info_list, args.output)
        print(f"\nğŸ‰ å¯¼å‡ºå®Œæˆ! æ€»é¢æ¿æ•°: {len(panel_info_list)}")
        print(f"è¯·æŸ¥çœ‹ExcelæŠ¥å‘Š: {excel_path}")
    else:
        print("\nâš ï¸ å¯¼å‡ºå®Œæˆï¼Œä½†æœªæ”¶é›†åˆ°ä»»ä½•é¢æ¿ä¿¡æ¯")


if __name__ == "__main__":
    export_dashboard_by_folder_name()
